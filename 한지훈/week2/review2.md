---
name: 📝 리뷰 과제
about: ML/DL 2장 ML 기본지식, 3장 ML 코딩
title: '[Week 2] 주차 리뷰 - 한지훈'
labels: ['review']
assignees: ''
---

## 주제
<!-- 이번 주차에 다룬 주요 주제를 작성해주세요 -->

- 기댓값 최대화(EM): 데이터의 기댓값으로 매개변수를 업데이트
- 오토인코더: 이미지를 더 낮은 차원으로 디코딩
- Precision, Recall Trade-off가 적용되는 실제 예시들
- nDCG: 추천시스템의 랭킹 매길 때 사용
- 저수지 샘플링: 전체 data의 일부 샘플링 시, data 순서에 따른 교체 빈도 차이나지 않게 
- TI-IDF: 문서에서 키워드 추출시 사용

## 내용
<!-- 주요 개념과 내용을 정리해주세요 -->

### 핵심 개념 1: nDCG 계산법과 적용

<aside>

### nDCG 정의

- 랭킹 추천 시스템에서 많이 사용되는 평가 지표
- 더 관심 있거나 관련성이 높은 아이템을 얼마나 잘 포함하고 있는지 평가
- 검색창에 10개의 아이템이 나타났을 때, 그 중 1, 3, 5, 7번 아이템이 관심 있는 아이템이라면 이를 바탕으로 랭킹이 제대로 매겨졌는지 평가

### 특징

- 검색 결과나 추천 목록에서 상위에 나타나는 문서일수록 더 큰 가중치를 가지며, **관련성이 높은 문서가 상위에 배치될수록 높은 점수**를 얻습니다.
- 단순히 정확도(Precision)나 재현율(Recall)만 고려하는 것이 아니라, 순위(position)까지 고려하기 때문에 **검색 및 추천 성능을 더 정밀하게 평가 가능**

### 계산

1. NDCG를 계산하기 위해 먼저 DCG (Discounted Cumulative Gain) 계산 필요

![image (9)](https://github.com/user-attachments/assets/9abbda36-603b-4510-a09a-3922c0f8c499)

- reli : **i번째 문서의 관련성 점수**
    - 보통 정수 값(0, 1, 2, 3, ...)으로 주어짐, 사용자의 피드백/평가 데이터 기반
    - 명시적 피드백: 사용자의 검색 결과/추천 항목에 대해 평가한 점수
    - 암묵적 피드백:  사용자 행동 데이터를 바탕으로 관련성 점수를 추정

- i : 검색 결과나 추천 목록에서의 **순위 (position)**

- 분모(log) 때문에 **상위(rank가 낮은) 문서일수록 가중치를 더 많이 받음**
    
    →상위에 위치한 문서일수록 더 높은 영향, 순위가 낮아질수록 기여도 감소
    

1. 이후 IDCG (Ideal DCG) 계산 필요(관련성 높은 문서가 가장 상위에 정렬된  DCG 값

3.  NDCG (Normalized DCG) 계산

![image (10)](https://github.com/user-attachments/assets/c39beee8-1b7c-4690-b3ed-db01d9145dc2)

- 이론상 최적의 정렬 시 점수와 비교 시 상대적으로 얼마나 정렬이 잘 되었는지 확인 가능
- 0~1 사이의 값, 1에 가까울수록 더 좋음

### 활용

검색 결과의 품질 측정

- **Google, Naver 등 검색 엔진:** 사용자가 입력한 쿼리에 대해 적절한 문서를 상위에 배치
- NDCG는 **검색 결과의 순서가 적절한지 평가**하는 데 유용

개인화 추천 품질 평가

- **Netflix, YouTube 등 추천 시스템: 사용자에게 얼마나 적절한 콘텐츠를 추천했는지 평가**
- **사용자가 좋아할만한 항목을 상위에 배치하는 것이 중요**

검색 광고 및 콘텐츠 추천 시스템

- **Google Ads, 네이버 광고 등:** 광고의 노출 순위가 **사용자의 관심사와 맞는지 평가**
- 사용자가 실제로 클릭한 광고와 추천된 광고의 순위를 비교하여 NDCG를 활용
</aside>

### 핵심 개념 2: Precision, Recall Trade-off가 적용되는 다른 예시

<aside>

### **Precision (정밀도)**

- **정의**: 양성으로 예측한 사례 중에서 실제로 양성인 비율
    
    ![image (11)](https://github.com/user-attachments/assets/f8cb8c5b-a787-45d0-8ae6-d8e5e53c5a72)
    
    - TP (True Positive): 실제 양성인데 양성으로 판정
    - FP (False Positive): 실제 음성인데 양성으로 판정
- **Precision이 높다는 의미**
    - 검사에서 양성 판정 시 실제로 감염되었을 가능성 높음
    - **False Positive 줄이는 데 초점**

### **Recall (재현율)**

- **정의**: 실제 양성 사례 중에서 양성으로 올바르게 예측한 비율
    
    ![image (12)](https://github.com/user-attachments/assets/1468047b-5d50-415c-99e9-3e5f944f7413)
    
    - FN (False Negative): 실제 양성인데 음성으로 판정
- **Recall이 높다는 의미**
    - 실제 양성 놓치지 않고 최대한 많이 발견
    - **False Negative 줄이는 데 초점**

이 개념은 여러 실상황에 적용이 가능하며, 그 중 금융 사기 탐지(Fraud Detection)에 집중

- **Precision (정밀도)**: 사기 거래라고 예측한 것 중 실제 사기일 확률
- **Recall (재현율)**: 실제 사기 거래 중에서 올바르게 탐지한 비율

**Precision과 Recall은 서로 trade-off 관계이며, 상황에 따라 어디에 집중할지 갈림**

### **Precision을 우선하는 경우**

- **적용 예시**: VIP 고객 또는 기업 고객의 금융 거래
- 목표: FP(정상 거래를 사기로 판단)를 줄여 **정상 사용자의 불편을 최소화**
- **단점**: 일부 사기 거래를 놓칠 가능성이 있음 (FN 증가)
- **결과**: 정상적인 거래가 차단되지 않지만, 일부 사기 거래를 탐지하지 못할 위험이 있음

### **Recall을 우선하는 경우**

- **적용 예시**: 대량 온라인 결제, 해외 거래 모니터링
- 목표: FN(사기 거래를 놓침)을 최소화하여 **최대한 많은 사기를 탐지**
- **단점**: 정상 사용자의 거래도 사기로 잘못 탐지될 가능성이 높음 (FP 증가)
- **결과:** 사기 거래를 놓칠 확률이 낮아지지만, 정상 사용자의 카드가 차단될 가능성이 높음
</aside>

## 참고 문헌
<!-- 참고한 자료의 제목과 링크를 작성해주세요 -->
1. [추천 시스템] NDCG https://velog.io/@whdgnszz1/추천-시스템-NDCG
2. [ML] Precision과 Recall의 Trade-off, 그리고 ROC Curve https://techblog-history-younghunjo1.tistory.com/101
