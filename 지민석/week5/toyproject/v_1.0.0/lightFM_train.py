import pandas as pd
import os
import json
import pickle
from lightfm import LightFM
from lightfm.data import Dataset

# ğŸ”¹ CSV íŒŒì¼ ê²½ë¡œ
LOGDATA_JSON = "logdata.json"
MODIFIED_DATA_CSV = "modified_data.csv"

# ğŸ”¹ JSON íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
with open(LOGDATA_JSON, "r", encoding="utf-8") as f:
    logdata = json.load(f)

# ğŸ”¹ pandas DataFrame ë³€í™˜
df = pd.DataFrame(logdata)
df['quiz_id'] = df['quiz_id'].astype(str)
df['user_id'] = df['user_id'].astype(str)

# ğŸ”¹ ë¬¸ì œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
data_df = pd.read_csv(MODIFIED_DATA_CSV, encoding="utf-8")
data_df['Question'] = data_df['Question'].astype(str)  # ğŸ”¥ `quiz_id`ì™€ ê°™ì€ íƒ€ì…(str)ìœ¼ë¡œ ë³€í™˜
item_features_df = data_df[['Question', 'Reason_0_3', 'Reason_K']].drop_duplicates()
item_features_df = item_features_df.rename(columns={'Question': 'quiz_id'})
item_features_df['quiz_id'] = item_features_df['quiz_id'].astype(str)

# ğŸ”¹ LightFM Dataset ìƒì„±
dataset = Dataset()
all_quiz_ids = item_features_df['quiz_id'].unique()

dataset.fit(
    users=df['user_id'].unique(),
    items=all_quiz_ids,
    item_features=[f"Reason_0_3_{x}" for x in item_features_df['Reason_0_3'].unique()] +
                  [f"Reason_K_{x}" for x in item_features_df['Reason_K'].unique()]
)

print(f"ğŸ”¥ dataset.fit ì‹¤í–‰ í›„ quiz_id ê°œìˆ˜: {len(dataset.mapping()[2])}")

# âœ… `dataset.fit_partial()` ì‹¤í–‰ ì „ì— ëˆ„ë½ëœ quiz_id ë³´ì™„
dataset.fit_partial(items=all_quiz_ids)

print(f"ğŸ”¥ dataset.fit_partial ì‹¤í–‰ í›„ quiz_id ê°œìˆ˜: {len(dataset.mapping()[2])}")

# ğŸ”¹ ì‚¬ìš©ìê°€ í‘¼ ë¬¸ì œ ëª©ë¡
user_attempts = df.groupby('user_id')['quiz_id'].apply(set).to_dict()

# ğŸ”¹ Negative ìƒ˜í”Œ ì¶”ê°€
all_quiz_ids_set = set(all_quiz_ids)
negative_samples = []

for user, solved in user_attempts.items():
    unsolved = list(all_quiz_ids_set - solved)  # ì‚¬ìš©ìê°€ í’€ì§€ ì•Šì€ ë¬¸ì œ
    for quiz_id in unsolved[:5]:  # ê° ì‚¬ìš©ìë‹¹ ìµœëŒ€ 5ê°œì˜ Negative ìƒ˜í”Œ ì¶”ê°€
        negative_samples.append((user, quiz_id, 0.1))

# ğŸ”¹ ê¸°ì¡´ ë°ì´í„° + Negative ìƒ˜í”Œ í¬í•¨
interaction_data = [(row['user_id'], row['quiz_id'], max(0.1, 1.0 if row['correct'] == 1 else 0.5)) for _, row in df.iterrows()]
interaction_data.extend(negative_samples)

# âœ… ìœ ì €-ë¬¸ì œ ìƒí˜¸ì‘ìš© í–‰ë ¬ êµ¬ì¶• (Negative ìƒ˜í”Œ í¬í•¨)
(interactions, weights) = dataset.build_interactions(interaction_data)

# âœ… ì•„ì´í…œ Feature í–‰ë ¬ êµ¬ì¶• (í˜•ì‹ ë³€í™˜)
item_features = dataset.build_item_features(
    ((row['quiz_id'], [f"Reason_0_3_{row['Reason_0_3']}", f"Reason_K_{row['Reason_K']}"]) for _, row in item_features_df.iterrows())
)

print("ğŸ”¹ ì•„ì´í…œ Feature ë§¤í•‘ ì™„ë£Œ")

# âœ… LightFM ëª¨ë¸ í•™ìŠµ (Negative ìƒ˜í”Œ í¬í•¨)
model = LightFM(loss='logistic')
model.fit(interactions, item_features=item_features, sample_weight=weights, epochs=10, num_threads=8)

# âœ… ëª¨ë¸ ì €ì¥
model_path = "lightfm_model.pkl"
dataset_path = "dataset.pkl"

with open(model_path, "wb") as f:
    pickle.dump(model, f)

with open(dataset_path, "wb") as f:
    pickle.dump(dataset, f)  # ğŸ”¥ dataset ì €ì¥

print(f"âœ… ëª¨ë¸ì´ ì €ì¥ë¨: {model_path}")
print(f"âœ… ë°ì´í„°ì…‹ì´ ì €ì¥ë¨: {dataset_path}")
print("âœ… LightFM ëª¨ë¸ í•™ìŠµ ì™„ë£Œ ë° ì €ì¥!")
